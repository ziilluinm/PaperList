Att机制<br>
【经典attention在seq2seq】<br>
paper传送门：<br>
<br>
代码传送门:<br>
<br>

【self-attention】Attention Is All You Need<br>
paper传送门：<br>
https://arxiv.org/abs/1706.03762<br>
代码传送门:<br>
https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py<br>

声纹识别
【ge2e】generalized end-to-end loss for speaker verification 
paper传送门：
https://arxiv.org/abs/1710.10467
代码传送门:
https://github.com/Janghyun1230/Speaker_Verification

【ge2e+att】
paper传送门：
 
代码传送门:
https://github.com/liyongze/lstm_speaker_verification

【crnn+att】Seq2Seq Attentional Siamese Neural Networks for Text-dependent Speaker Verification
paper传送门：
https://pan.baidu.com/s/1fXnqrsiL9RrEb3BLbQiSyw

【ENAS】Efficient Neural Architecture Search via Parameters Sharing
paper传送门：
https://arxiv.org/abs/1802.03268
代码传送门:
https://github.com/carpedm20/ENAS-pytorch
https://github.com/melodyguan/enas

【NAS综述】Neural Architecture Search: A Survey
paper传送门：
http://jmlr.org/papers/volume20/18-598/18-598.pdf



